{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1203e4-90fd-4b71-a364-c4fb319d37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f943dd-75a1-4473-80f7-88a328c48e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "\n",
    "def multi_unet_model(n_classes=2, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=3):\n",
    "#Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)  # Original 0.1\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)  # Original 0.1\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.1)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.1)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.1)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)  # Original 0.1\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)  # Original 0.1\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
    "    model.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f0093b-46f6-4c37-bd03-11019b71dcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 16  448         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256, 256, 16  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 16  2320        ['dropout[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 16  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 32  4640        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128, 128, 32  0           ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 32  9248        ['dropout_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64, 64, 64)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 64)   36928       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32, 32, 128)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 128)  147584      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0          ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 256)  295168      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 16, 16, 256)  0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 256)  590080      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 128)  131200     ['conv2d_9[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 256)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 32, 32, 128)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 128)  147584      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 64)  32832       ['conv2d_11[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 64)   73792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64, 64, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 64)   36928       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 32  8224       ['conv2d_13[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 64  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 32  18464       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128, 128, 32  0           ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 32  9248        ['dropout_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 16  2064       ['conv2d_15[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 32  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 16  4624        ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 256, 256, 16  0           ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 256, 16  2320        ['dropout_8[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 2)  34          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,122\n",
      "Trainable params: 1,941,122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = multi_unet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119ab9c9-1bf6-45d8-83f2-aa51b49d1059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert all the image form PNG to JPG\n",
    "# you compile this cell if and only if the images in your dataset is not in JPG but in PNG\n",
    "# This cell will convert. Otherwise pass\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def convert_images_to_jpg(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".png\") or filename.endswith(\".jpeg\") or filename.endswith(\".gif\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = Image.open(img_path)\n",
    "            new_filename = os.path.splitext(filename)[0] + \".jpg\"\n",
    "            new_img_path = os.path.join(directory, new_filename)\n",
    "            img.convert(\"RGB\").save(new_img_path, \"JPEG\")\n",
    "            os.remove(img_path)\n",
    "            print(f\"Converted {filename} to JPG\")\n",
    "\n",
    "# Specify the directory containing the images\n",
    "directory = \"C:/Users/DELL E7470/Desktop/Code/Fish_Dataset/Red Sea Bream/Red Sea Bream GT\"\n",
    "\n",
    "# Call the function to convert images to JPG\n",
    "convert_images_to_jpg(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd54300a-5741-4f96-89e7-400d7e2df4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "H=256\n",
    "W=256\n",
    "\n",
    "def read_image(x):\n",
    "    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "#def read_image(x):\n",
    "#    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "#    if x is not None:\n",
    "#        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB color format\n",
    "#        x = cv2.resize(x, (W, H))\n",
    "#        x = x / 255.0\n",
    "#        x = x.astype(np.float32)\n",
    "#    return x\n",
    "\n",
    "\n",
    "def read_mask(x):\n",
    "    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x.astype(np.int32)\n",
    "    return x\n",
    "\n",
    "\n",
    "def tf_dataset(x,y, batch=4):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y)) # Dataset object from Tensorflow\n",
    "    dataset = dataset.shuffle(buffer_size=100) \n",
    "    dataset = dataset.map(preprocess) # Applying preprocessing to every batch in the Dataset object\n",
    "    dataset = dataset.batch(batch) # Determine batch-size\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(2) # Optimization\n",
    "    return dataset\n",
    "        \n",
    "\n",
    "def preprocess(x,y):\n",
    "    def f(x,y):\n",
    "        x = x.decode()\n",
    "        y = y.decode()\n",
    "        image = read_image(x)\n",
    "        mask = read_mask(y)\n",
    "        return image, mask\n",
    "    \n",
    "    image, mask = tf.numpy_function(f,[x,y],[tf.float32, tf.int32])\n",
    "    mask = tf.one_hot(mask, num_classes, dtype=tf.int32)\n",
    "    image.set_shape([H, W, 3])    # In the Images, number of channels = 3. \n",
    "    mask.set_shape([H, W, num_classes])    # In the Masks, number of channels = number of classes. \n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b0391d-ac2c-4665-85fa-15f8880ea414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_dir = '../input/semantic-drone-dataset/dataset/semantic_drone_dataset'\n",
    "img_path = \"C:/Users/DELL E7470/Desktop/Code/Fish_Dataset/Red Sea Bream/Red Sea Bream\"\n",
    "mask_path =\"C:/Users/DELL E7470/Desktop/Code/Fish_Dataset/Red Sea Bream/Red Sea Bream GT\"\n",
    "\n",
    "names = list(map(lambda x: x.replace('.jpg', ''), os.listdir(img_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01f4b48-60be-419a-9b73-1b49490c9749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size : 720 images\n",
      "Val Size   :  180 images\n",
      "Test Size  :  100 images\n"
     ]
    }
   ],
   "source": [
    "X_trainval, X_test = train_test_split(names, test_size=0.1, random_state=19)\n",
    "X_train, X_val = train_test_split(X_trainval, test_size=0.2, random_state=19)\n",
    "\n",
    "print(f\"Train Size : {len(X_train)} images\")\n",
    "print(f\"Val Size   :  {len(X_val)} images\")\n",
    "print(f\"Test Size  :  {len(X_test)} images\")\n",
    "\n",
    "y_train = X_train\n",
    "y_test = X_test\n",
    "y_val = X_val\n",
    "\n",
    "img_train = [os.path.join(img_path, f\"{name}.jpg\") for name in X_train]\n",
    "mask_train = [os.path.join(mask_path, f\"{name}.png\") for name in y_train]\n",
    "img_val = [os.path.join(img_path, f\"{name}.jpg\") for name in X_val]\n",
    "mask_val = [os.path.join(mask_path, f\"{name}.png\") for name in y_val]\n",
    "img_test = [os.path.join(img_path, f\"{name}.jpg\") for name in X_test]\n",
    "mask_test = [os.path.join(mask_path, f\"{name}.png\") for name in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5f2cd2-d990-4128-bbfd-7760cf82a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=3\n",
    "\n",
    "train_dataset = tf_dataset(img_train, mask_train, batch = batch_size)\n",
    "valid_dataset = tf_dataset(img_val, mask_val, batch = batch_size)\n",
    "\n",
    "train_steps = len(img_train)//batch_size\n",
    "valid_steps = len(img_val)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf2a1bac-ad31-464c-bb1e-8945cc6ef7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 2), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.take(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a3fa9a-844a-4406-ae15-abdc88a2ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "H=256\n",
    "W=256\n",
    "\n",
    "\n",
    "def test_dataset(x, batch=4):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "    dataset = dataset.map(preprocess_test)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(2)\n",
    "    return dataset\n",
    "        \n",
    "\n",
    "def preprocess_test(x):\n",
    "    def f(x):\n",
    "        x = x.decode()\n",
    "        image = read_image(x)\n",
    "        return image\n",
    "    \n",
    "    image = tf.convert_to_tensor(tf.numpy_function(f, [x] , [tf.float32]))\n",
    "    image = tf.reshape(image, (H, W, 3))    # In the Images, number of channels = 3.  \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c83bbe-5cb3-4646-83a7-26cdbb28c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(min_delta=0.001, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7815d885-6012-4ff5-8b67-292a99f041b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nerror: OpenCV(4.6.0) C:\\b\\abs_d8ltn27ay8\\croot\\opencv-suite_1676452046667\\work\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\DELL E7470\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\DELL E7470\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\DELLE7~1\\AppData\\Local\\Temp\\__autograph_generated_filed2ku4b4p.py\", line 19, in f\n    mask = ag__.converted_call(ag__.ld(read_mask), (ag__.ld(y),), None, fscope_1)\n\n  File \"C:\\Users\\DELL E7470\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 335, in converted_call\n    return _call_unconverted(f, args, kwargs, options, False)\n\n  File \"C:\\Users\\DELL E7470\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 459, in _call_unconverted\n    return f(*args)\n\n  File \"C:\\Users\\DELL E7470\\AppData\\Local\\Temp\\ipykernel_7068\\2037341966.py\", line 24, in read_mask\n    x = cv2.resize(x, (W, H))\n\ncv2.error: OpenCV(4.6.0) C:\\b\\abs_d8ltn27ay8\\croot\\opencv-suite_1676452046667\\work\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_3246]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#just to check it works properly\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nerror: OpenCV(4.6.0) C:\\b\\abs_d8ltn27ay8\\croot\\opencv-suite_1676452046667\\work\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n\nTraceback (most recent call last):\n\n  File \"C:\\Users\\DELL E7470\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\DELL E7470\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\DELLE7~1\\AppData\\Local\\Temp\\__autograph_generated_filed2ku4b4p.py\", line 19, in f\n    mask = ag__.converted_call(ag__.ld(read_mask), (ag__.ld(y),), None, fscope_1)\n\n  File \"C:\\Users\\DELL E7470\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 335, in converted_call\n    return _call_unconverted(f, args, kwargs, options, False)\n\n  File \"C:\\Users\\DELL E7470\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 459, in _call_unconverted\n    return f(*args)\n\n  File \"C:\\Users\\DELL E7470\\AppData\\Local\\Temp\\ipykernel_7068\\2037341966.py\", line 24, in read_mask\n    x = cv2.resize(x, (W, H))\n\ncv2.error: OpenCV(4.6.0) C:\\b\\abs_d8ltn27ay8\\croot\\opencv-suite_1676452046667\\work\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_3246]"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "          steps_per_epoch=train_steps,\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=valid_steps,\n",
    "          epochs=1 #just to check it works properly\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ee440-0682-41e6-adb9-c2075cd85207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(original_images, mask_images, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3202637d-d449-4df2-addd-1405bf613020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluation = model.evaluate(original_images, mask_images, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc403215-5c1d-4747-84d9-4dd306dc8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute additional metrics\n",
    "\n",
    "predicted_masks = model.predict(original_images)\n",
    "iou = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "iou.update_state(mask_images, predicted_masks)\n",
    "iou_result = iou.result().numpy()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Loss: \", evaluation[0])\n",
    "print(\"Accuracy: \", evaluation[1])\n",
    "print(\"IoU: \", iou_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e6c4e-966c-44aa-ab19-4c086f44521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('unet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20a2b9-744b-49e2-800a-ef582df993a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0cc3b-afa1-4dea-8934-19cc0db539a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
